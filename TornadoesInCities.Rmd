---
title: "Tornadoes in Cities"
output: html_document
editor_options: 
  chunk_output_type: console
---

## Project one 

30th Severe Local Storms Conference
https://www.ametsoc.org/index.cfm/ams/meetings-events/ams-meetings/30th-conference-on-severe-local-storms1/?_zs=7VSBd1&_zl=N6GK8

Geographic variation in the expanding bull's eye effect: Why aren't we seeing more damaging tornadoes in urban areas?

Shifts in tornado frequency affecting metro and micro cities
An empirical study of the expanding bull's eye model. https://chubasco.niu.edu/ebe.htm


EF2/EF1 or EF3/EF1

Chance that a tornado creates EF2 or worse damage given that it creates at least EF1 damage. The assumption is, that all else being equal, the chance will be higher with more targets in an area for tornadoes to damage. Given the model of the expanding bull's eyes we would expect the ratio of EF2+/EF1+ tornadoes to be higher now then in the past. To the extent that that ratio is higher now for a given CBSA we consider it has having experienced an expanding bull's eye.

I think we need the denominator to be EF0 tornadoes (all tornadoes) otherwise the ratio of EF1 to EF0 might be going up faster than the ratio of EF2 to EF1 making it seem like there is no expanding bull's eye.

Expanding bull's eye is a simple conceptual model to illustrate how spatio-temporal development changes found in metropolitan regions have led to and will continue to place ever increasing number of built ‘targets’ in harm's way.

What cities (core-based statistical areas--cbsa) have seen the largest change in tornado frequency before/after 1985? Here I divide the tornado record into two 35-year epochs: 1986-2020 and 1951-1985 and count the number of tornadoes within each core-based statistical area during each epoch.

https://www.thetravel.com/usa-cities-tornado/
https://en.wikipedia.org/wiki/List_of_tornadoes_striking_downtown_areas_of_large_cities

Load packages.
```{r}
library(sf)
library(tidyverse)
library(tidycensus)
library(patchwork)
```

Get USA boundary map from {tidycensus}.
```{r}
us_states <- tigris::states(cb = TRUE, 
                            resolution = "20m") |>
  dplyr::filter(STUSPS %in% state.abb) 

us_states <- us_states |>
  sf::st_transform(crs = 32615) |>
  tigris::shift_geometry()
plot(us_states$geometry)
```

The Core-Based Statistical Areas (CBSA) are geographic locations neighboring urban areas of 10,000+ population and/or are socioeconomically tied to the urban center by commute proximity. Prior to the year 2000, these were collectively known as MSA- Metropolitan Statistical Areas and Micropolitan Statistical Areas. An exclusive feature of GreatData CBSA Data is that the population statistics are calculated annually. Therefore, the CBSA rank is based on a more recent population than typical census data classifications.

https://catalog.data.gov/dataset/tiger-line-shapefile-2019-nation-u-s-current-metropolitan-statistical-area-micropolitan-statist https://www2.census.gov/geo/tiger/TIGER2019/CBSA/tl_2019_us_cbsa.zip

Get the CBSA polygons.
```{r}
CBSA.sf <- st_read(dsn = here::here("data", "tl_2019_us_cbsa"), 
                   layer = "tl_2019_us_cbsa") |>
  st_transform(crs = st_crs(us_states))
```

Add a column with state abbreviations
```{r}
CBSA.sf$STUSPS <- stringr::str_sub(CBSA.sf$NAME, -2, -1)
```

Get the same set of polygons from the {tigris} package. Must be connected to the internet
```{r}
CBSA2.sf <- tigris::core_based_statistical_areas()
```

Get the tornado tracks. Tracks that recorded at least EF2 damage somewhere.
```{r}
if(!"1950-2020-torn-aspath" %in% list.files(here::here("data"))) {
download.file(url = "http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2020-torn-aspath.zip",
              destfile = here::here("data", "1950-2020-torn-aspath.zip"))
unzip(here::here("data", "1950-2020-torn-aspath.zip"), 
      exdir = here::here("data"))
}

Torn.sf <- st_read(dsn = here::here("data", "1950-2020-torn-aspath"), 
                   layer = "1950-2020-torn-aspath") |>
  st_transform(crs = st_crs(us_states)) |>
#  filter(yr >= 1951) |>
#  filter(yr >= 1995) |>
  filter(yr >= 2007) |>
#  mutate(Late = yr >= 1986) |>
#  mutate(Late = yr >= 2007) |>
  mutate(Late = yr >= 2013) |>
  filter(mag >= 0)
```

Create a map showing one CBSA and the intersecting tornado tracks. Colors from https://image-color-picker.com/hex-code-picker
```{r}
#NameC <- "Atlanta-Sandy Springs-Alpharetta, GA"
#NameC <- "Dallas-Fort Worth-Arlington, TX"
#NameC <- "Oklahoma City, OK"
#NameC <- "Wichita, KS"
#NameC <- "Springfield, IL"
#NameC <- "Des Moines-West Des Moines, IA"
#NameC <- "Chicago-Naperville-Elgin, IL-IN-WI"
#NameC <- "Rockford, IL"
#NameC <- "Jackson, MS"
#NameC <- "Nashville-Davidson--Murfreesboro--Franklin, TN"
#NameC <- "Birmingham-Hoover, AL"
NameC <- "New Orleans-Metairie, LA"

Torn2.sf <- Torn.sf |>
  filter(mag >= 0)

Area.sf <- CBSA.sf |>
  filter(NAME == NameC)

State.sf <- us_states |>
  filter(STUSPS == "LA")

Intersects <- Area.sf |>
  st_intersects(Torn2.sf) |>
  unlist()

AreaTors.sf <- Torn2.sf[Intersects, ]

nT <- AreaTors.sf |>
  group_by(Late) |>
  summarize(nT = n()) |>
  pull(nT)

ggplot() +
  geom_sf(data = State.sf, fill = "white") +
  geom_sf(data = Area.sf, color = "gray70") +
  geom_sf(data = AreaTors.sf, 
          mapping = aes(color = Late)) +
  scale_color_manual(values = c("#9E1FDE", "#5FDE1F"),
                     guide = "none") +
  labs(title = paste0("Approximate tracks of significant tornadoes\n", NameC),
       subtitle = paste0("Totals: 2007-2013 (purple): ", nT[1], 
                         paste0(", 2014-2020 (green): ", nT[2])))
```

Time series of ratio nEFk/nT.
```{r}
AreaTors.sf |>
  st_drop_geometry() |>
  group_by(yr) |>
  summarize(nT = sum(mag >= 0),
            nTk = sum(mag >= 1),
            ratio = nTk/nT) |>
  ggplot(mapping = aes(x = yr, y = ratio)) +
  geom_line() +
  geom_smooth()
```

All core-based statistical areas. Metro areas and micro areas. See {stars.Rmd} for creating a space-time object.
```{r}
Intersects <- CBSA.sf |>
  st_intersects(Torn.sf) |>
  unlist()
AreaTors.sf <- Torn.sf[Intersects, ]

Intersects.m <- CBSA.sf |>
  st_intersects(Torn.sf, sparse = FALSE)

TorCounts.sf <- 
  data.frame(GEOID = CBSA.sf$GEOID, 
             NAME = CBSA.sf$NAME,
             LSAD = CBSA.sf$LSAD,
             nT = rowSums(Intersects.m),
             geometry = CBSA.sf$geometry) |>
  st_as_sf()
```

Repeat for nT2 (EF2+) and then early and late.
```{r}
EF <- 3
Torn2.sf <- Torn.sf |>
  filter(mag >= EF) 

Intersects <- CBSA.sf |>
  st_intersects(Torn2.sf) |>
  unlist()
AreaTors.sf <- Torn2.sf[Intersects, ]

Intersects.m <- CBSA.sf |>
  st_intersects(Torn2.sf, sparse = FALSE)

TorCounts.sf$nT2 <- rowSums(Intersects.m)

Torn2.sf <- Torn.sf |>
  filter(!Late) 

Intersects <- CBSA.sf |>
  st_intersects(Torn2.sf) |>
  unlist()
AreaTors.sf <- Torn2.sf[Intersects, ]

Intersects.m <- CBSA.sf |>
  st_intersects(Torn2.sf, sparse = FALSE)

TorCounts.sf$nTearly <- rowSums(Intersects.m)

Torn2.sf <- Torn.sf |>
  filter(Late) 

Intersects <- CBSA.sf |>
  st_intersects(Torn2.sf) |>
  unlist()
AreaTors.sf <- Torn2.sf[Intersects, ]

Intersects.m <- CBSA.sf |>
  st_intersects(Torn2.sf, sparse = FALSE)

TorCounts.sf$nTlate <- rowSums(Intersects.m)

Torn2.sf <- Torn.sf |>
  filter(!Late, mag >= EF) 

Intersects <- CBSA.sf |>
  st_intersects(Torn2.sf) |>
  unlist()
AreaTors.sf <- Torn2.sf[Intersects, ]

Intersects.m <- CBSA.sf |>
  st_intersects(Torn2.sf, sparse = FALSE)

TorCounts.sf$nT2early <- rowSums(Intersects.m)

Torn2.sf <- Torn.sf |>
  filter(Late, mag >= EF) 

Intersects <- CBSA.sf |>
  st_intersects(Torn2.sf) |>
  unlist()
AreaTors.sf <- Torn2.sf[Intersects, ]

Intersects.m <- CBSA.sf |>
  st_intersects(Torn2.sf, sparse = FALSE)

TorCounts.sf$nT2late <- rowSums(Intersects.m)
```

Only examine areas with at least 15 tornadoes over the period 14-year period 2007-2020. 30 tornadoes over the period 1951-2020.
```{r}
TorCounts2.sf <- TorCounts.sf |>
  filter(nT >= 20) |>
  mutate(RatioEarly = nT2early/nTearly,
         RatioLate = nT2late/nTlate,
         EBE = RatioLate - RatioEarly,
         EBEtrue = EBE > 0)

TorCounts2.sf |>
  arrange(desc(EBE))

table(TorCounts2.sf$LSAD, TorCounts2.sf$EBEtrue)
```

Map all CBSAs with at least 15 tornadoes filled by EBE.
```{r}
X.sf <- TorCounts2.sf |>
  filter(LSAD == "M1")
#  filter(nTlate < nTearly)

( US_map <- ggplot(data = us_states) +
  geom_sf(fill = 'gray90',color = 'white', size = .15) +
  geom_sf(data = TorCounts2.sf, size = 0,
          mapping = aes(fill = EBEtrue)) + 
  scale_fill_manual(values = c("#1984E1", "#E11984"),
                    guide = 'none') +
  labs(title = "Relatively fewer very damaging tornadoes recently",
       subtitle = "Blue shows metro/micropolitan areas with a lower percentage of\nEF3+ tornadoes relative to all tornadoes since 2014",
       caption = "Gray regions are outside core-based metro/micropolitan statistical areas or\nhad fewer than 20 reported tornadoes during the period 2007-2020.\nData source: SPC") +
  theme_void() +
  theme(legend.title=element_blank()) )
```

Red shows metro/micropolitan areas with a greater percentage of EF3+ damaging tornadoes relative to all tornadoes since 2014. 

Contracting bull's eye.

Areas in red have had a larger percentage of damaging tornadoes (EF3+) or worse relative to all tornadoes since 2014.


```{r}
TorCounts.sf |>
  arrange(desc(nT))

TorCounts.sf |>
  slice_max(nT, n = 25) |>
  ggplot(mapping = aes(y = reorder(NAME, nT), x = nT)) +
  geom_point(size = 2, colour = "black") + 
  geom_segment(mapping = aes(yend = NAME, xend = 0), size = 1)+
  labs(y = "", x = "") +
  theme_minimal()
```

```{r}
Top25.sf <- TorCounts.sf |>
  slice_max(nT, n = 25)

( US_map <- ggplot(data = us_states) +
  geom_sf(fill = 'gray90', color = 'white', size = .15) +
  geom_sf(data = Top25.sf, size = 0,
          mapping = aes(fill = nT)) + 
  scale_fill_distiller(palette = "Oranges",
                       direction = 1, 
                       guide = 'none') + 
  theme_void() 
)

( P_plot <- ggplot(data = Top25.sf, 
                   mapping = aes(x = nT, y = reorder(NAME, nT), color = nT)) +
  geom_point(size = 2) +
  scale_color_distiller(palette = "Oranges",
                        direction = 1, 
                        guide = 'none') + 
  scale_x_continuous(limits = c(0, NA)) +
  labs(title = "Top 25 Metropolitan Areas by Number of Significant Tornadoes",
       subtitle = "1950-2019",
       y = "", x = "") + 
  theme_minimal() +
    theme(axis.ticks = element_blank(),
          panel.grid  = element_blank()) )

P_plot / US_map
```

Create a link/hover with map. https://twitter.com/kyle_e_walker/status/1397530708218892293 https://gist.github.com/walkerke/3628171efae66421c299c9f2dbee0f34

```{r}
library(ggiraph)

( US_map <- ggplot(data = us_states) +
  geom_sf(fill = 'gray90', color = 'white', size = .15) +
  geom_sf_interactive(data = Top25.sf, size = 0,
                      mapping = aes(fill = nT, color = nT, data_id = GEOID)) + 
  scale_fill_distiller(palette = "Oranges",
                       direction = 1, 
                       guide = 'none') + 
  scale_color_distiller(palette = "Oranges",
                       direction = 1, 
                       guide = 'none') + 
  theme_void() )

( P_plot <- ggplot(data = Top25.sf, 
                   mapping = aes(x = nT, y = reorder(NAME, nT), color = nT)) +
  geom_point_interactive(size = 2, mapping = aes(data_id = GEOID)) +
  scale_color_distiller(palette = "Oranges",
                        direction = 1, 
                        guide = 'none') +
  scale_x_continuous(limits = c(0, NA)) +
  labs(title = "Top 25 Metropolitan Areas by\n Number of Significant Tornadoes",
       subtitle = "1950-2019",
       y = "", x = "") + 
    theme_minimal() +
    theme(axis.ticks = element_blank(),
          panel.grid  = element_blank())  )

girafe(ggobj = P_plot / US_map, width_svg = 8, height_svg = 6) |>
  girafe_options(opts_hover(css = "fill:cyan;stroke:cyan;"))
```

Counts grouped early and late.
```{r}
Intersects <- CBSA.sf |>
  st_intersects(Torn.sf) |>
  unlist()
AreaTors.sf <- Torn.sf[Intersects, ]

AreaTors.sf$GEOID <- rep(CBSA.sf$GEOID, 
                         times = rowSums(Intersects.m))

TorCounts.df <- AreaTors.sf |>
  st_drop_geometry() |>
  group_by(GEOID, Late) |>
  summarize(nT = n()) |>
  ungroup()

( Diff.df <- TorCounts.df |>
  pivot_wider(names_from = Late, 
              values_from = nT) |>
  rename(After1985 = `TRUE`,
         Before1985 = `FALSE`) |>
  mutate(Difference = After1985 - Before1985,
         DiffPerc = Difference/Before1985 * 100) |>
  drop_na() )

sum(Diff.df$Difference > 0)
sum(Diff.df$Difference < 0)
```

Map of changes across all CBSAs group by +/- and 0.
```{r}
Diff.df <-
  Diff.df |>
   mutate(Change = case_when(Difference == 0 ~ 'No change',
                             Difference < 0 ~ 'Fewer since 1985',
                             Difference > 0 ~ 'More since 1985'))

All.sf <- CBSA.sf |>
  right_join(Diff.df,
             by = "GEOID") 

( US_map <- ggplot(data = us_states) +
  geom_sf(fill = 'gray90',color = 'white', size = .15) +
  geom_sf(data = All.sf, size = 0,
          mapping = aes(fill = Change)) + 
  scale_fill_manual(values = c("#84E119", "#E11984", "#1984E1")) +
  labs(title = "                     The shifting U.S. tornado threat (EF2 or worse damage)",
       caption = "    Gray regions are outside of core-based statistical areas or there were no EF2+ tornadoes either before or after 1985 in record from 1950-2019.") +
  theme_void() +
  theme(legend.title=element_blank()) )
```

Top 10 and bottom 10 combined.
```{r}
Upward <- Diff.df |>
  slice_max(Difference, n = 100) |>
  mutate(Tendency = "Upward")

Downward <- Diff.df |>
  slice_min(Difference, n = 100) |>
  mutate(Tendency = "Downward")

Both <- rbind(Upward, Downward)

Both <- Both |>
  left_join(CBSA.sf,
            by = "GEOID") 
```

Plot a slope graph.
```{r}
library(ggrepel)

ggplot(Both) +
  geom_segment(mapping = aes(x = .4, xend = .6, 
                             y = Before1985, yend = After1985, 
                             color = Tendency)) +
  scale_color_manual(values = c("#E69F00", "#CC79A7"), guide = 'none') +
  scale_x_continuous(limits = c(0, 1)) +
  theme(panel.background = element_blank(),
        panel.grid=element_blank(),
        axis.ticks=element_blank(),
        axis.text=element_blank(),
        panel.border=element_blank()) +
  geom_text(data = Both[Both$Tendency == "Upward", ],
            mapping = aes(x = .62, y = After1985, 
                          label = paste(After1985, NAME, sep = "   ")), hjust = 0, size = 3.5, color = "#CC79A7") +
  geom_text(data = Both[Both$Tendency == "Downward", ], 
            mapping = aes(x = .38, y = Before1985, 
                          label = paste(NAME, Before1985, sep = "   ")), hjust = 1, size = 3.5, color = "#E69F00") +
  geom_text(data = Both[1, ], 
            mapping = aes(label = "1950-1984", x = .38, y = 1), hjust = 1, size = 4) +
  geom_text(data = Both[1, ], 
            mapping = aes(label = "1985-2018", x = .62, y = 1), hjust = 0, size = 4) +
  geom_segment(data = Both[1,],
               mapping = aes(x = .45, y = 1, xend = .55, yend = 1), color = "gray70",
               arrow = arrow(angle = 20, length = unit(2, "mm"), type = "closed")) +
  labs(title = "The shifting tornado threat",
       subtitle = "Cities with the largest change in number of significant tornadoes (EF2 or worse damage)",
       x = "", y = "")
```

Create a link/hover with map. https://twitter.com/kyle_e_walker/status/1397530708218892293 https://gist.github.com/walkerke/3628171efae66421c299c9f2dbee0f34

```{r}
Both <- Both |>
  select(GEOID, After1985, Before1985, Difference)

Both.sf <- CBSA.sf |>
  right_join(Both,
            by = "GEOID") 

( US_map <- ggplot(data = us_states) +
  geom_sf(fill = 'gray90',color = 'white', size = .15) +
  geom_sf(data = Both.sf, size = 0,
          mapping = aes(fill = Difference > 0)) + 
  scale_fill_manual(values = c("#E69F00", "#CC79A7"),
                    guide = 'none') +
  theme_void() )

( P_plot <- ggplot(data = Both.sf, 
                   mapping = aes(x = Difference, y = reorder(NAME, Difference), 
                                 color = Difference > 0)) +
  geom_point(size = 2.5) +
  geom_vline(xintercept = 0, color = "gray80") +
  scale_color_manual(values = c("#E69F00", "#CC79A7"),
                      guide = 'none') +
  scale_x_continuous(limits = c(-65, 65), position = "top") +
  labs(title = "Top changes in significant tornado counts in CBSAs since 1985",
       y = "", x = "Fewer tornadoes      More Tornadoes") + 
  theme_minimal() +
  theme(axis.title.x = element_text(margin = margin(t = 2, unit = "cm")), 
        axis.ticks = element_blank(),
        panel.grid  = element_blank(),
        axis.line.x = element_line(arrow = grid::arrow(length = unit(2, "mm"), 
                                                       angle = 20, 
                                                       type = "closed", 
                                                       ends = "both"))) )

P_plot / US_map
```

## Project two

EF ratings rural versus urban impacts. Whether a tornado hits an urban area or not determines the amount damage that can occur. Here we attempt to quantify the magnitude of this effect. Specifically we ask how much less likely (on average) is EF3 (or worse) damage in rural areas compared with urban areas?

Load packages.
```{r}
library(sf)
library(tidyverse)
library(tidycensus)
library(patchwork)
library(tmap)
```

```{r}
Plains <- c("TX", "OK", "KS", "NE", "SD", "ND")
Area.sfc <- USAboundaries::us_states(states = Plains) |>
  st_union() 

Urban.sf <- tigris::urban_areas() # must be connected to the internet

Area.sfc <- Area.sfc |>
  st_transform(crs = st_crs(Urban.sf))

Urban.sf <- Urban.sf |>
  st_crop(Area.sfc)
```

Map check
```{r}
tmap_mode("view")

tm_shape(Area.sfc) +
  tm_borders() +
  tm_shape(Urban.sf) +
  tm_borders() 
```

Get the tornado tracks since 2007 (start of EF rating).
```{r}
Torn.sf <- st_read(dsn = "1950-2019-torn-aspath", 
                   layer = "1950-2019-torn-aspath") |>
  st_transform(crs = st_crs(Urban.sf)) |>
  filter(mag >= 0 & yr >= 2007) |>
  mutate(Length = len * 1609.34,
         Width = wid * .9144,
         maxEF = mag,
         Date = as.Date(date),
         Year = yr,
         Month = mo) |>
  select(Date, Year, Month, maxEF, Length, Width, slat, slon) |>
  st_crop(Area.sfc)
```

Mark all tornadoes that intersect urban areas.
```{r}
Intersects <- Urban.sf |>
  st_intersects(Torn.sf) |>
  unlist()

Torn.sf$row <- 1:nrow(Torn.sf)

Torn.sf <- Torn.sf |>
  mutate(Urban = row %in% Intersects)

tm_shape(Urban.sf) +
  tm_borders() +
  tm_shape(Torn.sf[Torn.sf$Urban, ]) +
  tm_lines(col = "red") +
  tm_shape(Torn.sf[!Torn.sf$Urban, ]) +
  tm_lines(col = "blue")
```

Areas
```{r}
areaRegion <- 
  Area.sfc |> 
  st_bbox() |>
  st_as_sfc() |>
  st_area()

areaUrban <-
  Urban.sf |>
  st_area() |>
  sum()

areaUrban / areaRegion * 100
```

Urban areas cover 1.4% of the region.

Group tornadoes by urban or rural and examine EF rating statistics.
```{r}
( UrbanRuralStats.df <- Torn.sf |>
  st_drop_geometry() |>
  group_by(Urban) |>
  summarize(nT = n(),
            Avg = mean(maxEF),
            Median = median(maxEF),
            Min = min(maxEF),
            Max = max(maxEF),
            AvgL = mean(Length),
            MedianL = median(Length),
            AvgW = mean(Width),
            MedianW = median(Width)) )

x <- UrbanRuralStats.df
x$nT[x$Urban] / (x$nT[x$Urban] + x$nT[!x$Urban]) * 100
```

Urban tornadoes (tornadoes affecting urban areas) account for 8.4% of all tornadoes.

On average the EF rating is lower for tornadoes in rural areas. Before jumping to conclusions we need to examine other factors like the fact that rural areas occupy a larger percentage of the west compared to the east.

Use a cumulative logistic model to quantify the effect rural areas have on the EF rating conditioning on path characteristics, location, and month.

Are tornadoes that affect urban areas longer? Yes. Also what about demographic data. Are damaging tornadoes in rich urban areas more likely to get a higher rating compared with damaging tornadoes in poor urban areas? This is an interesting question but is hard to answer given the gradient in wealth within large urban areas. Maybe using {tidycensus} https://twitter.com/mrworthington/status/1446910612471173121

DAGs and confounding variables
https://journals.sagepub.com/doi/full/10.1177/2515245917745629

Start by describing the ordered distribution of maximum EF ratings with intercepts. Begin with a histogram of maximum EF rating per tornado.
```{r}
#devtools::install_github("rmcelreath/rethinking")

( FreqByEF.df <- Torn.sf |>
  st_drop_geometry() |>
  group_by(Urban, maxEF) |>
  summarize(nT = n()) |>
    mutate(pr_k = case_when(Urban ~ nT / sum(nT),
                           !Urban ~ nT / sum(nT)),
           cum_pr_k = cumsum(pr_k),
           log_cum_odds = rethinking::logit(cum_pr_k),
           ys = cum_pr_k - pr_k,
           Names = case_when(Urban ~ "Urban",
                             !Urban ~ "Rural")) )

ggplot(FreqByEF.df, 
       mapping = aes(x = maxEF, y = pr_k)) + 
  geom_point() + 
  geom_segment(aes(xend = maxEF, yend = 0)) +
  facet_wrap(~ Names) +
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = "Maximum EF Rating", y = "Percentage",
      title = "Tornadoes are more likely to get a higher damage rating in/near urban areas") +
  theme_minimal()

ggplot(FreqByEF.df,
       mapping = aes(x = maxEF, y = cum_pr_k, color = Names)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(minor_breaks = 0:5) +
    xlab("Maximum EF Rating") +
    ylab("Cumulative Proportion") +
  theme_minimal()

ggplot(FreqByEF.df,
       mapping = aes(x = maxEF, y = log_cum_odds, color = Names)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(NA, 10) ) +
  scale_x_continuous(limits = c(0, 4), minor_breaks = 0:4) +
  xlab("Maximum EF Rating") +
  ylab("Log-Cumulative-Odds") +
  theme_minimal()

ggplot(FreqByEF.df, 
       mapping = aes(x = maxEF, y = cum_pr_k)) +
  geom_segment(aes(x = maxEF, xend = maxEF, y = ys, yend = cum_pr_k), size = 1.3, color = "gray70") +
  geom_point() +
  geom_line() +
  facet_wrap(~ Names) +
  scale_y_continuous(limits = c(0, 1)) +
    xlab("Maximum EF Rating") +
    ylab("Cumulative Proportion") +
  theme_minimal()
```
Figure: Relative frequency of tornadoes by maximum EF rating grouped by urban and rural occurrence. Only tornadoes occurring in a boundying box encompassing Texas to North Dakota are considered. Log-cumulative odds of a tornado by maximum EF rating grouped by urban and rural occurrence.

Note that the cumulative logit for the highest EF rating is infinity. This is because log(1/(1 - 1)) = $\infty$. This is always the case so we do not need a parameter for it. We get it for free from the law of total probability. So for $K$ = 6 possible maximum EF ratings we only need $K$ - 1 = 5 intercepts.

Cumulative probability and ordered likelihood. The horizontal axis displays possible observable damage ratings, from 0 through 5. The vertical axis displays cumulative probability. The points show cumulative probability. These keep getting higher with each successive EF rating. The gray line segments show the discrete probability of each EF rating. These are the likelihoods that go into Bayes’ theorem.

In code form
$$
\begin{aligned} 
\hbox{R}_i &\sim \hbox{Ordered}(\mathbf{p}) \\ 
\hbox{logit}(p_k) &= \alpha_k \\
\alpha_k &\sim \hbox{Normal}(0, 10)
\end{aligned}
$$
The Ordered distribution is a categorical distribution that takes a vector $p = \{p_0, p_1, p_2, p_3, p_4\}$ of probabilities for each EF rating below the highest (EF5). Each response value $k$ in this vector is defined by its link to an intercept parameter ($\alpha_k$).

To include predictor variables, we define the log-cumulative-odds of each EF rating $k$ as a sum of its intercept $\alpha_k$ and a typical linear model. Suppose for  example we want to add a predictor $x$ to the model. We do this by defining a linear model $\phi_i = \beta x_i$. Then each cumulative logit becomes
$$
\begin{aligned}
\log \frac{\Pr(y_i \le k)}{1 - \Pr(y_i \le k)} &= \alpha_k - \phi_i \\
\phi_i &= \beta x_i
\end{aligned}
$$

The form ensures the correct ordering of the EF ratings while allowing for changes in the likelihood of each individual value as the predictor $x_i$ changes value. As the log-cumulative odds of every EF value ($k$) below the maximum decreases, the probability mass shifts upwards toward higher EF ratings.

$$
\phi_i = \beta_{Year}Year_i + \beta_L L_i + \beta_W W_i + \beta_{Urban}Urban_i + \beta_M M_i
$$

where Year_i indicates the year of tornado i and L_i and W_i indicate the length and width of damage path for tornado i. Month (M_i) is a random offset so the coefficient \beta_M is a vector of length 12. 

Use the {ordinal} and {lme4} packages. Christensen (2019). ordinal - Regression Models for Ordinal Data. R package version 2019.12-10. https://CRAN.R-project.org/package=ordinal

https://user2021.r-project.org/participation/technical_notes/t186/technote/
```{r}
library(ordinal)
library(lme4)
```

Prepare the data
```{r}
df <- Torn.sf |>
  st_drop_geometry() |>
  mutate(maxEFf = factor(Torn.sf$maxEF, ordered = TRUE), # response variable must be an ordered factor
         PathAreaS = log10(Length * Width),
         YearS = as.numeric(scale(Year)), #as.numeric() function avoids creating lists
         LonS = as.numeric(scale(slon))) |>
  select(maxEFf, Urban, PathAreaS, YearS, LonS)
```

Fit cumulative logistic model using the `clm()` function from the {ordinal} package.
```{r}
m0 <- ordinal::clm(maxEFf ~ 1, data = df)
m1 <- ordinal::clm(maxEFf ~ Urban, data = df)
m2 <- ordinal::clm(maxEFf ~ Urban + PathAreaS, data = df)
anova(m1, m2)
```

Also try the `polr()` function from the {MASS} package.
```{r}
library(MASS)
m1polr <- polr(maxEFf ~ Urban, 
               data = df)
brant::brant(m1polr)
m2polr <- polr(maxEFf ~ Urban + PathAreaS, 
               data = df)
brant::brant(m2polr)
```

Testing proportional odds assumption: https://medium.com/evangelinelee/brant-test-for-proportional-odds-in-r-b0b373a93aa2

Failed the proportional odds assumption. 

We might want to group EF4 & EF5 together and retest.

We can try the `vglm()` function from the {VGAM} package. http://users.stat.ufl.edu/~aa/ordinal/R_examples.pdf

Compare `parallel = TRUE` against `parallel = FALSE`. 

Need to reform the data into a table of counts.

Urban  EF0  EF1 EF2 ...
TRUE   #
FALSE  #
```{r}
( dfw <- df |>
  group_by(Urban, maxEFf) |>
  summarize(nT = n() ) |>
  pivot_wider(names_from = maxEFf,
              values_from = nT) )
names(dfw)[2:7] <- c("EF0", "EF1", "EF2", "EF3", "EF4", "EF5")
```

Will need to make `PathAreaS` categorical (e.g., small, medium, large)
```{r}
df <- df |>
  mutate(PathAreaSc = cut(PathAreaS, 
                          breaks = c(-Inf,
                                     quantile(PathAreaS, probs = c(1/3, 2/3)),
                                     Inf),
                          labels = c("small","medium","large")))
```

```{r}
library(VGAM)

m1vglm <- vglm(maxEFf ~ Urban, 
               family = cumulative(parallel = TRUE), 
               data = df)

m1vglm_a <- vglm(cbind(EF0, EF1, EF2, EF3, EF4, EF5) ~ Urban,
                 family = cumulative, 
                 data = dfw)
```

```{r}
dfw2 <- df |>
  group_by(Urban, PathAreaSc, maxEFf) |>
  summarize(nT = n() ) |>
  pivot_wider(names_from = maxEFf,
              values_from = nT) |>
  replace(is.na(dfw2), 0)

names(dfw2)[3:8] <- c("EF0", "EF1", "EF2", "EF3", "EF4", "EF5")

m2vglm_a <- vglm(cbind(EF0, EF1, EF2, EF3, EF4, EF5) ~ Urban + PathAreaSc,
                 family = cumulative, 
                 data = dfw2)

```

Or we can try a multinomial logistic regression. https://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/

```{r}
library(nnet)

m1 <- multinom(maxEFf ~ Urban, data = df)
m2 <- multinom(maxEFf ~ Urban + PathAreaS, data = df)
summary(m1)
summary(m2)

anova(m1, m2)

( z <- summary(m2)$coefficients/summary(m2)$standard.errors )
( p <- (1 - pnorm(abs(z), 0, 1)) * 2) 

exp(coef(m1))
exp(coef(m2))

head(pp <- fitted(m2))

m3 <- multinom(maxEFf ~ Urban * PathAreaS, data = df)
anova(m2, m3)
```



Interpreting the coefficients of an ordinal logistic regression. https://stats.idre.ucla.edu/other/mult-pkg/faq/ologit/
The ordinal logistic regression is parameterized as
$$
logit(P(Y \leq j)) = \beta_{j0} - \eta_1 x_1
$$
where 
$$\eta_1 = -\beta_1 $$
Suppose we want to see whether the binary predictor urban/rural predicts an ordinal outcome of EF ratings. Due to the parallel lines assumption (failed in our case), even though we have 6 rating categories, the coefficient of urban/rural stays the same across the categories. The two equations for `Urban = TRUE` ($x_1 = 1$) and `Urban = FALSE` ($x_1 = 0$) are
$$
logit(P(EF \leq j |x_1 = 1)) = \beta_{j0} - \eta_1 \\
logit(P(EF \leq j |x_1 = 0)) = \beta_{j0}
$$
Then
$$
logit(P(EF \leq j |x_1 = 1)) - logit(P(EF \leq j |x_1 = 0)) = -\eta_1
$$

```{r}
summary(m1)
```

The output shows that for tornadoes impacting urban areas, the log odds of getting an EF0 rating (versus an EF1 or higher rating) is $-\hat \eta_1 = - .88$ or .88 points _lower_ than tornadoes impacting rural areas.

Instead of interpreting the odds of getting an EFj-th category or less, we can interpret the odds of getting a greater than the EFj-th category by exponentiating $\eta$ itself. $\exp(\hat \eta) = \exp(.88) = 2.42$ which means that urban tornadoes have 2.42 times the odds of having a higher EF rating across all EF categories.

```{r}
newdat <- data.frame(Urban = c(TRUE, FALSE))
( phat <- predict(object = m1, newdat, type = "p") )
```

```{r}
newdat <- data.frame(Urban = c(TRUE, FALSE), PathAreaS = mean(df$PathAreaS))
( phat <- predict(object = m2, newdat, type = "p") )
```



Use the {brms} package. Start by setting the family and the model formula. Get priors. 
```{r}
library(brms)

family <- brms::cumulative(threshold = "flexible")
family <- brms::multinomial()

df$maxEFc <- as.character(df$maxEFf)

formula <- maxEFf ~ 1
formula <- maxEFc ~ 1

get_prior(formula, 
          data = df, 
          family = family)

prior <- brm(formula = formula,
             data = df,
             family = family,
             prior = set_prior("student_t(3, 0, 2.5)", class = "Intercept"),
             sample_prior = "only",
             seed = 9121)
prior_out <- predict(prior, probs = c(0, 1))
head(prior_out)

fit0 <- brm(formula = formula,
           data = df,
           family = family,
           prior = set_prior("student_t(3, 0, 2.5)", class = "Intercept"),
           seed = 9121)
fixef(fit0)

fit0_out <- predict(fit0, probs = c(0, 1))
head(fit0_out)
```

Since there are a lot of tornadoes, the posterior for each intercept is quite precisely estimated, as we can see from the small standard deviations. To get cumulative probabilities back:
```{r}
rethinking::logistic(fixef(fit0))
```

These are the same (nearly) as the values in `cum_pr_k` that we computed above. But now we also have a posterior distribution around these values, and we’re ready to add predictor variables to the model.

Model with predictors. Start with some default priors (for example `"normal(0,5)"` for the `class = "b"`). Sample from the priors and check the predictive distribution of the response. Adjust the priors accordingly. https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations
```{r}
family <- brms::cumulative(threshold = "flexible")
formula <- maxEFf ~ Urban

get_prior(formula, 
          data = df, 
          family = family)

prior2 <- brm(formula = formula,
              data = df,
              family = family,
              prior = c(set_prior("normal(0, 1)", class = "b"),
                        set_prior("student_t(3, 0, 2.5)", class = "Intercept")),
              sample_prior = "only",
              control = list(max_treedepth = 15),
              seed = 9121)

prior_out2 <- predict(prior2, probs = c(0, 1))
```

With `normal(0, 5)` the probabilities are highest for the first and sixth categories. This u-shaped distribution is diminished by using `normal(0, 1)`.

Fit models. Examine the difference in the Urban term between a model with only the Urban term and models that use a more complete set of explanatory variables. Maybe use log of path area to scale. Try cs(PathAreaS) to see if the relationship changes for different EF ratings.
```{r}
df$UrbanI <- as.integer(df$Urban)
df$maxEF1I <- as.integer(df$maxEF1)

formula1 <- maxEF1 ~ Urban
formula1a <- maxEF1I ~ cs(Urban); family = "sratio"
formula2 <- maxEF1 ~ Urban + PathAreaS
formula2a <- maxEF1 ~ Urban + cs(PathAreaS); family = "sratio"
formula2b <- maxEF1 ~ Urban * PathAreaS
formula3 <- maxEF1 ~ Urban + PathAreaS + YearS
formula4 <- maxEF1 ~ Urban + PathAreaS + YearS + LonS
formula4b <- maxEF1 ~ Urban + PathAreaS + LonS
formula4a <- maxEF1I ~ cs(Urban) + PathAreaS + YearS + LonS; family = "sratio"
formula5 <- maxEF1 ~ Urban*YearS + PathAreaS + LonS
formula6 <- maxEF1 ~ Urban*YearS + PathAreaS + LonS + (1|Month)
fit2b <- brm(formula = formula2b,
            data = df,
            family = family,
            prior = c(set_prior("normal(0, 1)", class = "b"),
                     set_prior("student_t(3, 0, 2.5)", 
                               class = "Intercept")),
            control = list(max_treedepth = 15),
            chains = 2,
            seed = 7818721)

fixef(fit1)

#save(fit4a, file = "fit4a.RData")
#load("fit1.RData")
fit1_out <- predict(fit1, probs = c(0, 1))
```

The positive coefficient on the UrbanTRUE[1] indicates that when we go from rural to urban the proportion of storms rated EF1 relative to EF0 is higher. The positive coefficient on the UrbanTRUE[2] indicates that when we go from rural to urban areas the proportion of storms rated EF2 relative to EF1 is higher but there is no statistical significance for the higher EF ratings.

Compare models.
```{r}
fit1 <- add_criterion(fit1, "waic")
fit2 <- add_criterion(fit2, "waic")
fit3 <- add_criterion(fit3, "waic")
fit4 <- add_criterion(fit4, "waic")
fit5 <- add_criterion(fit5, "waic")
fit6 <- add_criterion(fit6, "waic")


loo_compare(fit1, fit2, fit3, fit4, fit5, fit6, criterion = "waic")

fit1 <- add_criterion(fit1, "loo")
fit2 <- add_criterion(fit2, "loo")
fit3 <- add_criterion(fit3, "loo")
fit4 <- add_criterion(fit4, "loo")
fit5 <- add_criterion(fit5, "loo")
fit6 <- add_criterion(fit6, "loo")
fit4b <- add_criterion(fit4b, "loo")

loo_compare(fit1, fit2, criterion = "loo")
```

Test for practical equivalence.
```{r}
bayestestR::equivalence_test(fit1)
bayestestR::equivalence_test(fit2)
```

Extracting and visualizing tidy draws from {brms} models. https://cran.r-project.org/web/packages/tidybayes/vignettes/tidy-brms.html
```{r}
library(tidybayes)

get_variables(fit1)

fit2 |>
  spread_draws(b_LengthS, b_UrbanTRUE) |>
  head(20)

fit2 |>
  spread_draws(b_LengthS, b_UrbanTRUE) |>
  median_qi(b_LengthS, b_UrbanTRUE)

fit2 |>
  gather_draws(b_LengthS, b_UrbanTRUE) |>
  median_qi()
```

Add a plot. Fixed effects. Highest density interval.
```{r}
( fit2 |> 
  gather_draws(b_LengthS, b_UrbanTRUE) |>
  median_hdi(.width = c(.95, .66)) |>
  ggplot(aes(y = .variable, x = .value, xmin = .lower, xmax = .upper)) +
  geom_pointintervalh() +
  geom_vline(xintercept = 0, col = "gray70") +
  scale_y_discrete(labels = c("Path Length", "Urban?")) +
#  scale_x_continuous(limits = c(NA, NA), breaks = c(-.2, 0, .2)) +
  ylab("") + xlab("Coefficient Value") +
  theme_minimal() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) )
```

Conditional effect of rural on EF rating.
```{r}
gg <- conditional_effects(fit4b, categorical = TRUE)
ggUrban <- gg[[1]] |>
#    mutate(maxEF = as.integer(cats__) - 1)
  filter(cats__ != 1)
levels(ggUrban$cats__) <- c("EF0", "EF1", "EF2", "EF3", "EF4", "EF5")

( pfit2 <- ggplot(ggUrban, 
       mapping = aes(x = Urban, y = estimate__ * 100, label = cats__, color = Urban)) +
  geom_text() +
  scale_color_manual(values = c("#1FDE92", "#DE1F6B"), guide = "none") +
  scale_y_log10(limits = c(.01, 100), labels = c(".01%", ".1%", "1%", "10%", "100%"), breaks = c(.01, .1, 1, 10, 100)) +
#  scale_y_log10() +
  scale_x_discrete(labels = c("Rural", "Urban")) + 
  labs(caption = "Chance a tornado causes EF-level damage given location. Data source: NOAA",
       title = "Tornadoes impacting rural areas are less likely to get a higher\ndamage rating relative to those impacting urban areas",
       x = "", y = "") +
  theme_minimal() )

gg <- conditional_effects(fit2, categorical = TRUE)
x <- gg[[1]] |>
  mutate(maxEF = as.integer(cats__) - 1) |>
  filter(maxEF >= 3) |>
  group_by(Urban) |>
  summarize(sumEstimate = sum(estimate__)) |>
  pull(sumEstimate)
(x[2] - x[1]) / x[2]

```

How much less likely (on average) is EF3 (or worse damage) to be found after a tornado impact in rural areas compared with urban areas?

The effect size of the Rural term diminishes with additional significant factors in the model. The mean reduction in the chance of at least EF3 damage in rural areas (2.4%) relative to urban areas (5.6%) is about 57%. The _conditional_ mean reduction in the chance of at least EF3 damage in rural areas (1.15%) relative to urban areas (1.96%) is about 41%.

Posterior predictions on the cumulative probability scale.
```{r}
library(modelr)
library(tidyr)

fitted1 <- df |>
  data_grid(Urban = c(TRUE, FALSE)) |>
  add_epred_draws(fit1, ndraws = 100)

out1 <- fitted1 |>
  group_by(.draw) |>
  arrange(.category) |>
  mutate(cs = cumsum(.epred),
         Model = "fit1") 
levels(out1$.category) <- c("EF0", "EF1", "EF2", "EF3", "EF4", "EF5")

fitted2 <- df |>
  data_grid(PathAreaS = median(df$PathAreaS), 
            Urban = c(TRUE, FALSE)) |>
  add_epred_draws(fit2, ndraws = 100)

out2 <- fitted2 |>
  group_by(.draw) |>
  arrange(.category) |>
  mutate(cs = cumsum(.epred),
         Model = "fit2") 
levels(out2$.category) <- c("EF0", "EF1", "EF2", "EF3", "EF4", "EF5")

out <- rbind(out1, out2)

( p_model <- ggplot(out[out$.category != "EF0", ], 
       mapping = aes(x = .epred, y = Urban)) +
  stat_interval() +
  scale_y_discrete(labels = c("Rural", "Urban")) +
  coord_flip() +
  scale_x_log10(limits = c(NA, 1)) +
  facet_wrap(~ Model + .category, nrow = 2) +
  ylab("Urban/Rural") +
  labs(title = "Estimated chance of a tornado causing EF-level damage",
       subtitle = "Rural versus urban areas",
       x = "", y = "", colour = "Confidence\ninterval", caption = "U.S. Great Plains over the period 2007-2019") +
  theme_minimal() )
```

Be careful here. Size influences urban/rural (mean path area 4.4 sq km for tornadoes hitting urban areas and 1.7 sq km for tornadoes in rural areas) and both size and urban/rural influence EF rating. This creates a chain in a DAG.

Compute the distance between the tornado and the nearest urban polygon.
```{r}
distFromUrban <- numeric()
for(i in seq_len(nrow(Torn.sf))){
  distFromUrban[i] <- min(st_distance(Torn.sf[i, ], Urban2020.sf))
}
```

Get census data from these CBSAs. https://walker-data.com/tidycensus/articles/spatial-data.html
```{r}
options(tigris_use_cache = TRUE)

( Augusta <- get_decennial(geography = "tract",
                           variables = "P001001",
                           year = 2000,
                           state = "GA", 
                           county = "Richmond", 
                           geometry = TRUE,
                           summary_var = "P001001") )
```

## Project three

Historical significant (EF2+) tornadoes from Grazulis. Data were extracted from the Grazulis volumes by Tyler Fricker and his associates.

County level comparisons of counts over the common period 1950-1989 (see project cty-counts). Which states show the highest/lowest correlation between the two datasets in terms of number of EF2+ tornadoes? Why? What does it mean for a state to have a large correlation?

Load packages.
```{r}
library(sf)
library(tidyverse)
library(tmap)
```

Get the historical tornado data
```{r}
unzip(zipfile = "SignificantTornadoes.zip")

OldTorn.sf <- st_read(dsn = "SignificantTornadoes", 
                      layer = "SignificantTornadoes") |>
  arrange(date, time) |>
  select(-county) |>
  filter(mag %in% c("F2", "F3", "F4", "F5")) # note some transcription errors

table(OldTorn.sf$mag)
range(OldTorn.sf$Year)

df <- OldTorn.sf |>
  st_drop_geometry() |>
  group_by(Year) |>
  summarize(nF2 = sum(mag == "F2"),
            nF3p = sum(mag == "F3" | mag == "F4" | mag == "F5"),
            ratio = nF3p / nF2)

  ggplot(data = df,
         mapping = aes(x = Year, y = nF3p)) +
  geom_line()
```

Get the modern tornado data
```{r}
Torn.sf <- st_read(dsn = "1950-2019-torn-aspath", 
                   layer = "1950-2019-torn-aspath") |>
  filter(yr > 1950) |>
  filter(mag >= 2 | fat > 0) |>
  mutate(mag = paste0("F", mag)) |>
  select(om, st, date, time, fat, inj, wid, len, mag, 
         Year = yr, Month = mo, Day = dy,
         slon, slat, elon, elat)

table(Torn.sf$mag)
```

Combine the old and new tornado databases.
```{r}
AllTorn.sf <- rbind(OldTorn.sf, Torn.sf)

df <- AllTorn.sf |>
  st_drop_geometry() |>
#  filter(Year > 1989) |>
  group_by(Year) |>
  summarize(nF2 = sum(mag == "F2"),
            nF3p = sum(mag == "F3" | mag == "F4" | mag == "F5"),
            nF4p = sum(mag == "F4" | mag == "F5"),
            nF2p = nF2 + nF3p,
            ratio = nF3p / nF2)

  ggplot(data = df,
         mapping = aes(x = Year, y = nF3p)) +
  geom_line()

acf(df$nF3p) # peaks at 8 & 9 years
```

```{r}
library(EMD)

out <- emd(df$nF3p, boundary = "periodic")

```

Compute tornado energy for tornadoes in `AllTorn.sf`. Compute the pacf() on the annual energy.


Include only tornadoes near cities. Create a {stars} object from the tornado data using city buffers. 

See `stars.Rmd` in project `space-time`.
```{r}
library(stars)
library(USAboundaries)
library(USAboundariesData)

cities_1880 <- us_cities("1880-01-01") |>
  filter(population > 1000)

tm_shape(cities_1880) + 
  tm_bubbles()

cities_selected <- us_cities("1880-01-01") |>
  filter(state_abbr %in% c("NE", "MO", "MS", "AR", "OH", "TX", "TN", "CO", "IA", "AL", "GA")) |>
  filter(city %in% c("Lincoln", "Kansas City", "St. Louis", "Vicksburg", 
                     "Columbus", "Nashville", "Memphis", "Little Rock", "Dallas",
                     "Denver", "Des Moines", "Dubuque", "Montgomery", "Atlanta")) |>
#  filter(state_abbr %in% c("AR", "OH", "TX", "TN")) |>
#  filter(city %in% c("Columbus", "Nashville", "Memphis", "Little Rock", "Dallas")) |>
#  filter(city %in% c("Little Rock")) |>
  st_buffer(dist = 50000)

tm_shape(cities_selected) + 
  tm_borders(lwd = 2, col = "red")
```

Get tornado counts intersecting the city buffers.
```{r}
counts.v <- NULL
for(year in 1880:2019){
  tracks <- AllTorn.sf %>%
    filter(Year == year)
  mtrx <- st_intersects(cities_selected, 
                        tracks, 
                        sparse = FALSE)
  counts.v <- c(counts.v, rowSums(mtrx))
}

library(lubridate)
years <- year(seq(as_date("1880-01-01"), 
                  as_date("2019-01-01"), 
                  by = "year"))

d <- st_dimensions(location = cities_selected$city, 
                   year = years)

( counts.st <- st_as_stars(list(counts = matrix(counts.v, ncol = length(years))), dimensions = d) )

counts.df <- as.data.frame(counts.st)


ggplot(data = counts.df,
       mapping = aes(x = year, y = counts)) +
  geom_point() +
  facet_wrap(~ location, scales = "free_y") +
  geom_smooth() +
  theme_minimal()

countsAll.df <- counts.df |>
  group_by(year) |>
  summarize(nT = sum(counts))
```

All together
```{r}
cities_selected_U <- st_union(cities_selected)
counts.v <- NULL
for(year in 1880:2019){
  tracks <- AllTorn.sf %>%
    filter(Year == year)
  mtrx <- st_intersects(cities_selected_U, 
                        tracks, 
                        sparse = FALSE)
  counts.v <- c(counts.v, rowSums(mtrx))
}

counts.df <- data.frame(year = 1880:2019, counts = counts.v)

ggplot(data = counts.df,
       mapping = aes(x = year, y = counts)) +
  geom_point() +
  geom_smooth() +
  theme_minimal()

counts.df |>
  filter(year <= 2019) |>
  summarize(Avg = mean(counts),
            Var = var(counts),
            Ratio = Var/Avg)

ratio <- NULL
for(i in 1:10000){
  x = rpois(n = 140, lambda = .478)
  ratio[i] <- var(x) / mean(x)
}
range(ratio)
hist(ratio)
```

As the circumference around the city increases, the less likely the annual counts assume a Poisson distribution. This makes sense. If the underlying processes is Poisson with a rate parameter that depends on the chance that the tornado hits a target. For small circumferences that chance will be high and remain equally high over time. For large circumferences that chance will be low early and increase over time as the city expands to include more targets (expanding bulls-eye).

Get historical county boundaries. Cities are points only.
```{r}
library(USAboundaries)
library(USAboundariesData)

cities_1880 <- us_cities("1880-01-01")

plot(st_geometry(cities_1880))
title("U.S. cities on January 1, 1880")

counties_KS_1880 <- us_counties("1880-01-01", states = "Kansas")
plot(st_geometry(counties_KS_1880))
title("County boundaries in Kansas in 1880")

counties_KS_1980 <- us_counties("1980-01-01", states = "Kansas")
plot(st_geometry(counties_KS_1980))
```

History of tornadoes in/near Mayfield, KY.
```{r}
Mayfield_KY <- us_cities("2010-01-01") |> 
  filter(city == "Mayfield", state_abbr == "KY") |>
  st_buffer(dist = 10000)

library(tmap)

tmap_mode("view")

tm_shape(Mayfield_KY) +
  tm_borders()

m <- st_intersects(OldTorn.sf,
                   Mayfield_KY,
                   sparse = FALSE)

Mayfield_KY_OldTorn.sf <- OldTorn.sf |> 
  subset(m)

m <- st_intersects(Torn.sf,
                   Mayfield_KY,
                   sparse = FALSE)

Mayfield_KY_Torn.sf <- Torn.sf |> 
  subset(m)
```

Big days
```{r}
AllTorn.sf |>
  st_drop_geometry() |>
  group_by(date) |>
  summarize(nT = n()) |>
  filter(nT >= 10) |>
  mutate(Date = as.Date(date),
         Year = year(Date)) |>
  group_by(Year) |>
  summarize(nBigDays = n()) |>
ggplot(aes(x = Year, y = nBigDays)) +
  geom_point() +
  geom_smooth() +
  theme_minimal()
```


